{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e241469",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96179e87",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f87355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 19:04:02.883102: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-20 19:04:02.884509: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-20 19:04:02.914284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-20 19:04:02.915386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-20 19:04:03.508832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b5daf89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e0293",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d640719",
   "metadata": {},
   "source": [
    "# Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb6277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('Training_set',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294a2e7",
   "metadata": {},
   "source": [
    "# Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66aee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('Testing_set',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bb53c",
   "metadata": {},
   "source": [
    "# Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d2c40",
   "metadata": {},
   "source": [
    "# Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfded3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 19:04:05.283182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-20 19:04:05.283538: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27dd13",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cdbbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[128, 128, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f3cd2",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "154730f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf0e72",
   "metadata": {},
   "source": [
    "# Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f4292be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf83e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ad1c2",
   "metadata": {},
   "source": [
    "# Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a42c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc579a",
   "metadata": {},
   "source": [
    "# Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af97a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98892419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcdb26ba",
   "metadata": {},
   "source": [
    "# Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68e5e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884835b6",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bdb33",
   "metadata": {},
   "source": [
    "# Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ba4e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07ce46",
   "metadata": {},
   "source": [
    "# Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a054aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "63/63 [==============================] - 71s 1s/step - loss: 1.3816 - accuracy: 0.2803 - val_loss: 1.3079 - val_accuracy: 0.3430\n",
      "Epoch 2/25\n",
      "63/63 [==============================] - 71s 1s/step - loss: 1.3039 - accuracy: 0.3422 - val_loss: 1.2656 - val_accuracy: 0.3837\n",
      "Epoch 3/25\n",
      "63/63 [==============================] - 70s 1s/step - loss: 1.2724 - accuracy: 0.3770 - val_loss: 1.2177 - val_accuracy: 0.4223\n",
      "Epoch 4/25\n",
      "63/63 [==============================] - 71s 1s/step - loss: 1.2430 - accuracy: 0.4160 - val_loss: 1.2026 - val_accuracy: 0.4078\n",
      "Epoch 5/25\n",
      "63/63 [==============================] - 69s 1s/step - loss: 1.2185 - accuracy: 0.4270 - val_loss: 1.1521 - val_accuracy: 0.4658\n",
      "Epoch 6/25\n",
      "63/63 [==============================] - 71s 1s/step - loss: 1.1781 - accuracy: 0.4552 - val_loss: 1.1171 - val_accuracy: 0.4868\n",
      "Epoch 7/25\n",
      "63/63 [==============================] - 87s 1s/step - loss: 1.1486 - accuracy: 0.4827 - val_loss: 1.1041 - val_accuracy: 0.5128\n",
      "Epoch 8/25\n",
      "63/63 [==============================] - 73s 1s/step - loss: 1.1004 - accuracy: 0.5052 - val_loss: 1.0174 - val_accuracy: 0.5570\n",
      "Epoch 9/25\n",
      "63/63 [==============================] - 74s 1s/step - loss: 1.0768 - accuracy: 0.5155 - val_loss: 0.9780 - val_accuracy: 0.5735\n",
      "Epoch 10/25\n",
      "63/63 [==============================] - 70s 1s/step - loss: 1.0227 - accuracy: 0.5452 - val_loss: 0.8953 - val_accuracy: 0.6315\n",
      "Epoch 11/25\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.9495 - accuracy: 0.5853 - val_loss: 0.8298 - val_accuracy: 0.6580\n",
      "Epoch 12/25\n",
      "63/63 [==============================] - 63s 994ms/step - loss: 0.9066 - accuracy: 0.6208 - val_loss: 0.7689 - val_accuracy: 0.6877\n",
      "Epoch 13/25\n",
      "63/63 [==============================] - 65s 1s/step - loss: 0.8612 - accuracy: 0.6507 - val_loss: 0.8179 - val_accuracy: 0.6575\n",
      "Epoch 14/25\n",
      "63/63 [==============================] - 63s 999ms/step - loss: 0.8462 - accuracy: 0.6457 - val_loss: 0.6696 - val_accuracy: 0.7352\n",
      "Epoch 15/25\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.7516 - accuracy: 0.6982 - val_loss: 0.6659 - val_accuracy: 0.7308\n",
      "Epoch 16/25\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.7077 - accuracy: 0.7168 - val_loss: 0.5556 - val_accuracy: 0.7850\n",
      "Epoch 17/25\n",
      "63/63 [==============================] - 62s 991ms/step - loss: 0.6391 - accuracy: 0.7525 - val_loss: 0.4909 - val_accuracy: 0.8145\n",
      "Epoch 18/25\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.5771 - accuracy: 0.7810 - val_loss: 0.3966 - val_accuracy: 0.8612\n",
      "Epoch 19/25\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.5338 - accuracy: 0.8048 - val_loss: 0.3803 - val_accuracy: 0.8635\n",
      "Epoch 20/25\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 0.4837 - accuracy: 0.8217 - val_loss: 0.2893 - val_accuracy: 0.9090\n",
      "Epoch 21/25\n",
      "63/63 [==============================] - 63s 995ms/step - loss: 0.4432 - accuracy: 0.8340 - val_loss: 0.2984 - val_accuracy: 0.8972\n",
      "Epoch 22/25\n",
      "63/63 [==============================] - 62s 992ms/step - loss: 0.4231 - accuracy: 0.8468 - val_loss: 0.2823 - val_accuracy: 0.9020\n",
      "Epoch 23/25\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.3668 - accuracy: 0.8643 - val_loss: 0.2182 - val_accuracy: 0.9220\n",
      "Epoch 24/25\n",
      "63/63 [==============================] - 65s 1s/step - loss: 0.3511 - accuracy: 0.8783 - val_loss: 0.1720 - val_accuracy: 0.9430\n",
      "Epoch 25/25\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 0.2942 - accuracy: 0.8928 - val_loss: 0.1452 - val_accuracy: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f163223db10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abc034",
   "metadata": {},
   "source": [
    "# Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca34b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhu/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8290b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'trained_model.h5'\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a62ab5",
   "metadata": {},
   "source": [
    "# Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d04a386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Single_Predictions/angry1.jpg'\n",
    "img = image.load_img(image_path, target_size=(128, 128))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16218707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0, 'happy': 1, 'relaxed': 2, 'sad': 3}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f1baf788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "emotion_classes = ['angry', 'happy', 'relaxed', 'sad'] \n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b5824df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emotion = emotion_classes[predicted_class_index]\n",
    "confidence = predictions[0][predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "645b3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: angry\n",
      "Confidence: 0.9994039535522461\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "print(f\"Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cb82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
